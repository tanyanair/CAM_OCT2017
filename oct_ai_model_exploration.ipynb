{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. What is Machine Learning / AI ?\n",
    "Instead of coding a program with specific instructions, the goal of machine learning/AI is to \"train\" an algorithm so it can make predictions for itself. \n",
    "\n",
    "### Example: Snapchat filter\n",
    "In a Snapchat, or other apps you can download on a phone, you can select filters like \"bunny ears\" or \"sunglasses\".\n",
    "\n",
    "![image](./snapchat.png)\n",
    "(source: https://www.flickr.com/photos/63405864@N04/27265562262)\n",
    "\n",
    "When you have the filter on, the sunglasses are (most of the time) in the right spot. How does it know how to do that if the program has never seen your face before? There are two main steps involved that the developers do:\n",
    "1. Train an AI model to predict the location of eyes/ears from a big, labelled dataset of human faces.\n",
    "2. When running on your phone. The same model predicts where your eyes are, and a separate function will put an image of sunglasses over that location on your face.\n",
    "\n",
    "### Example: Avatar livestream\n",
    "The same technique can be used to create a live avatar of YOU!\n",
    "https://pose-animator-demo.firebaseapp.com/camera.html\n",
    "On this webpage, with your webcam enabled, you will see a live video stream of yourself, and an cartoon avatar that will move when you move, and make the same faces you make.\n",
    "\n",
    "!!! Will not work if you are using your webcam on Zoom or another application !!! \n",
    "\n",
    "\n",
    "# 2. AI in Healthcare\n",
    "In addition to a lot of the cool looking demo's out there. There are a lot of applications of AI that have the potential to make huge, positive impacts on our communitys. One of those applications is in the healthcare industry. By looking at patient images (could be X-Ray, brain MRI, lung CT), we can potentially train AI models to make predictions about whether patients are at risk for disease, and speed up their interactions with doctors, clinicians when they are high-risk.\n",
    "\n",
    "One interesting body part that tells us a lot of information about a person's health is the eye. There are a lot of diseases that can be detected early on, when looking at images of the eye. On top of vision-related issues like near-sightedness, with different kinds of images of the eye, doctors are able to help in the diagnosis of diabetes. While researcher is ongoing, one day it may be be possible to also help the diagnosis heart conditions, alzheimers (in some cases) when these diseases are at early stages.\n",
    "\n",
    "## Example: Looking at the retina with an OCT eye scan.\n",
    "The retina is a part of your the back of your eye:\n",
    "\n",
    "![retina](retina.png)\n",
    "(source: https://en.wikipedia.org/wiki/Retina#/media/File:Three_Main_Layers_of_the_Eye.png)\n",
    "\n",
    "By using a imaging technique called OCT (Optical Coherence Tomography), we can compute an image similar to the one below that visualizes the retina, fovea, and other regions usefull for disease diagnosis. This is what a healthy, normal oct looks like. We will see images of what unhealthy eyes look like when we open up our dataset further on.\n",
    "\n",
    "![oct image](oct_normal.png)\n",
    "(source: https://commons.wikimedia.org/wiki/File:SD-OCT_Macula_Cross-Section.png)\n",
    "\n",
    "In practice, doctors look at these OCT images when trying to disagnose retinal diseases, and guide treatment for their patients. \n",
    "\n",
    "\n",
    "# 3. Can we train an AI model to predict different disease types from an eye scan?\n",
    "That is our goal for today! Our task is to build an AI model and train it to predict whether a patient's eye is healthy, or shows characteristics of one of the following diseases:\n",
    "1. healthy\n",
    "2. Diabetic Macular Edema (DME) - patient has fluid in the retinal layers of the eye. A sign of diabetes.\n",
    "2. Choroidal neovascularization (CNV) - patient has blood veins growing in between retinal layers. Patient will have vision loss.\n",
    "3. Drusen - \"tiny pebbles of debris\" are visible in the retinal layers. These debris are made of fat molecules.\n",
    "\n",
    "Today we will cover the complete cycle of training an AI model including:\n",
    "1. Loading and visualizing the data\n",
    "2. Building the AI model\n",
    "3. Training the AI model\n",
    "4. Visualizing the AI model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tls5m1zVLFjg"
   },
   "source": [
    "# Let's Start Coding!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mGxu-kfgLX_f"
   },
   "source": [
    "## 1. Download OCT2017 dataset\n",
    "This will download the dataset to the location this code runs in. *It will not download it to your computer*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 309
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 226141,
     "status": "ok",
     "timestamp": 1569013480329,
     "user": {
      "displayName": "Tuyen Ho Sy",
      "photoUrl": "",
      "userId": "07941590644325363329"
     },
     "user_tz": -420
    },
    "id": "4WnZYEhAy_0w",
    "outputId": "39c1a330-25d9-4e64-c6c1-c36583225233"
   },
   "outputs": [],
   "source": [
    "# Download dataset\n",
    "!wget https://data.mendeley.com/datasets/rscbjbr9sj/2/files/5699a1d8-d1b6-45db-bb92-b61051445347/OCT2017.tar.gz\n",
    "\n",
    "# Decompress dataset\n",
    "!tar -zxf OCT2017.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "x97l--gCLu0I"
   },
   "source": [
    "## 2. Setup Programming Environment\n",
    "In industry, we never start from scratch. We use tools that make it easier to load data, build AI models, and train and visualize them. Let's make sure these tools are in our coding environment!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ehSSO-Rqza_g"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2, preprocess_input\n",
    "from tensorflow.keras.applications import VGG16, DenseNet121, InceptionV3, InceptionResNetV2, ResNet50\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "\n",
    "MODEL_BANK = {\n",
    "    'VGG16': VGG16,\n",
    "    'DenseNet121': DenseNet121,\n",
    "    'InceptionV3': InceptionV3,\n",
    "    'InceptionResNetV2': InceptionResNetV2,\n",
    "    'ResNet50': ResNet50\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "X0ZObTZRL7V7"
   },
   "source": [
    "## 3. Preprocess dataset\n",
    "Here we will setup the code that will iterate through the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4978,
     "status": "ok",
     "timestamp": 1569013852154,
     "user": {
      "displayName": "Tuyen Ho Sy",
      "photoUrl": "",
      "userId": "07941590644325363329"
     },
     "user_tz": -420
    },
    "id": "ulKOSk_bL-pb",
    "outputId": "95af13e8-14f2-407d-fe15-d3a91e3a6e58"
   },
   "outputs": [],
   "source": [
    "batch_size = 32   # what happens when this increases/decreases?\n",
    "img_size = 224\n",
    "input_img_size = (224,224,3)\n",
    "class_labels_short = ['CNV', 'DME', 'DRUSEN', 'NORMAL']\n",
    "class_labels_long = ['choroidal neovascularization', 'diabetic macular edema', 'drusen', 'normal']\n",
    "\n",
    "\n",
    "###############################################\n",
    "# Training Data\n",
    "train_data_preprocessing = ImageDataGenerator(\n",
    "      brightness_range=None, \n",
    "      shear_range=0.0,        # try changing me!\n",
    "      zoom_range=0.0,         # try changing my value!\n",
    "      horizontal_flip=False,  # try setting me to True\n",
    "      vertical_flip=False,    # try setting me to True\n",
    "      rescale=None, \n",
    "      preprocessing_function=preprocess_input,\n",
    "      data_format=None, \n",
    "      validation_split=0.2)\n",
    "\n",
    "train_data = train_data_preprocessing.flow_from_directory(\n",
    "    'OCT2017/train',\n",
    "    target_size=(img_size, img_size),\n",
    "    color_mode='rgb',\n",
    "    shuffle=True,\n",
    "    subset='training',\n",
    "    batch_size=batch_size)\n",
    "\n",
    "validation_data = train_data_preprocessing.flow_from_directory(\n",
    "    'OCT2017/train',\n",
    "    target_size=(img_size, img_size),\n",
    "    color_mode='rgb',\n",
    "    shuffle=True,\n",
    "    subset='validation',\n",
    "    batch_size=batch_size)\n",
    "\n",
    "###############################################\n",
    "# Testing Data\n",
    "test_data_preprocessing = ImageDataGenerator(\n",
    "    preprocessing_function=preprocess_input)\n",
    "\n",
    "test_data = test_data_preprocessing.flow_from_directory(\n",
    "                'OCT2017/test',\n",
    "                target_size=(img_size, img_size),\n",
    "                color_mode='rgb',\n",
    "                shuffle=False,\n",
    "                batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_some_images(train_iter, nb_image_rows=15, nb_images_per_row=3):\n",
    "    nb_images_per_row = 3\n",
    "    train_iter.batch_size=nb_images_per_row\n",
    "    for i in range(nb_image_rows):\n",
    "        x_batch, y_batch = train_iter.next()\n",
    "        x_batch += 1\n",
    "        x_batch /= 2\n",
    "\n",
    "        plt.figure()\n",
    "        fig, axes =  plt.subplots(nrows=1, ncols=nb_images_per_row, figsize=(20,15))\n",
    "        for ax, x, y in zip(axes, x_batch, y_batch):\n",
    "            ax.imshow(x)\n",
    "            ax.set_title(class_labels_long[np.argmax(y)])\n",
    "            ax.set_xticks([])\n",
    "            ax.set_yticks([])\n",
    "\n",
    "        plt.show()\n",
    "    \n",
    "plot_some_images(validation_data, nb_image_rows=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "n1XOQ4hUPBXH"
   },
   "source": [
    "## 4. Build AI model\n",
    "An AI model consists of multiple layers. The input layer is connected to the input images. The middle layers perform several, sequental computations on the data. And the final, output layer will predict which class the model thinks the image belongs to. There are many \"tricks\" researchers use to speed up model training, and we will use some of them today:\n",
    "* using different `base model` architectures. There are many different AI architectures out there. Different architectures have different strengths in terms of speed, accuracy, computational expense.\n",
    "* using pretrained weights. In the code below you will see `weights=imagenet`. This line is telling the program to use the parameters of a different AI task (natural image classification) as a starting point for our task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5344,
     "status": "ok",
     "timestamp": 1569013863455,
     "user": {
      "displayName": "Tuyen Ho Sy",
      "photoUrl": "",
      "userId": "07941590644325363329"
     },
     "user_tz": -420
    },
    "id": "je6kK5QYPEk7",
    "outputId": "16048ad6-4dc2-40d5-d962-be35b310bd2b"
   },
   "outputs": [],
   "source": [
    "num_classes = 4\n",
    "\n",
    "# a function to help us build the model\n",
    "def build_model(base_model_name='VGG16', freeze_base=False):\n",
    "    assert base_model_name in MODEL_BANK.keys(), f'model name be one of {MODEL_BANK.keys()}, you entered {model_name} '\n",
    "    base_model = MODEL_BANK[base_model_name](\n",
    "                    weights='imagenet',\n",
    "                    input_shape=input_img_size,\n",
    "                    include_top=False)\n",
    "    for layer in base_model.layers:\n",
    "        if freeze_base:\n",
    "            layer.trainable = False\n",
    "        else:\n",
    "            layer.trainable = True\n",
    "        \n",
    "    x = base_model.layers[-3].output\n",
    "    x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "    x = tf.keras.layers.Dense(128, activation='relu')(x) # what happens if we add a few more of these layers?\n",
    "    x = tf.keras.layers.Dense(num_classes, activation='softmax')(x)\n",
    "    model = tf.keras.models.Model(inputs=base_model.input, outputs=x)\n",
    "    \n",
    "    return model\n",
    "\n",
    "\"\"\"\n",
    "Below, we call the function above with a particular base-model name. \n",
    "We can also try using a different base model name:\n",
    "   * VGG16, DenseNet121, InceptionV3,  InceptionResNetV2, ResNet50\n",
    "What happens if we set freeze_base=True?\n",
    "\"\"\"\n",
    "oct_model = build_model(base_model_name='VGG16', freeze_base=False)\n",
    "oct_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "X19VIWwPRlsV"
   },
   "source": [
    "## 5. Train Model\n",
    "In the code below, we train the model using the data we visualized above. We can play around with some parameters here:\n",
    "* learning_rate - a number that controls fast or slow the model learns. If we set it too low, the model will learn very slowly, and we'll be waiting a long time for the model to get a good accuracy. If we set it too high, the model will get confused from trying to learn too quickly! \n",
    "* n_epochs - the number of times to iterate through the entire dataset. For now anywhere between 1-5 is a good choice.\n",
    "* n_steps_per_epoch - When we train the model, we show it a few examples at a time. This number controls how many batches of data we show the model, before deciding to stop and make a new epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 462
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 9491526,
     "status": "ok",
     "timestamp": 1568808109481,
     "user": {
      "displayName": "Tuyen Ho Sy",
      "photoUrl": "",
      "userId": "07941590644325363329"
     },
     "user_tz": -420
    },
    "id": "pA5i1kJ3RngM",
    "outputId": "8ad63443-05af-453d-a354-884ecd8511c8"
   },
   "outputs": [],
   "source": [
    "# hyperparameters. What happens when we change these values\n",
    "learning_rate = 0.0001 # what happens if we decrease this?\n",
    "n_epochs = 3\n",
    "n_train_steps_per_epoch = 500 # entire dataset = 66788 // batch_size \n",
    "n_valid_steps_per_epoch = 100 # entire valid set = 16696 // batch_size\n",
    "\n",
    "# Save checkpoint\n",
    "weights_name = \"weights.h5\"\n",
    "weight_saver = ModelCheckpoint(\n",
    "    weights_name, \n",
    "    monitor=\"val_acc\", \n",
    "    verbose=1, \n",
    "    save_best_only=True,\n",
    "    save_weights_only=True)\n",
    "\n",
    "# Optimizer\n",
    "optimizer = tf.keras.optimizers.Adam(lr=learning_rate)\n",
    "oct_model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['acc'])\n",
    "\n",
    "# Train the model!!\n",
    "trained_oct_model = oct_model.fit(\n",
    "    train_data,\n",
    "    epochs=n_epochs,\n",
    "    steps_per_epoch=n_train_steps_per_epoch,\n",
    "    validation_data=validation_data,\n",
    "    validation_steps=n_valid_steps_per_epoch,\n",
    "    callbacks=[weight_saver])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "c0t8PoAht6l1"
   },
   "source": [
    "## 6. Summarize Accuracy\n",
    "Let's visualize how our model got better over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 292
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 976,
     "status": "ok",
     "timestamp": 1568818829304,
     "user": {
      "displayName": "Tuyen Ho Sy",
      "photoUrl": "",
      "userId": "07941590644325363329"
     },
     "user_tz": -420
    },
    "id": "2k_sMGvmt_GH",
    "outputId": "70f4d82d-42df-408d-9852-437c83464259"
   },
   "outputs": [],
   "source": [
    "plt.plot(list(range(n_epochs)), trained_oct_model.history['val_acc'], label='validation accuracy')\n",
    "plt.plot(list(range(n_epochs)), trained_oct_model.history['acc'], label='training accuracy')\n",
    "                                                        \n",
    "plt.ylim(bottom=0)\n",
    "plt.xlabel('Epoch', fontsize=20)\n",
    "plt.ylabel('Accuracy', fontsize=20)\n",
    "plt.legend(loc='lower right')   \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YzYyddNxv2fg"
   },
   "source": [
    "## 7. Label Heat Map\n",
    "Now that we have trained our model, we can visualize where, for a given input image, the model is looking when it makes its prediction. Below are some helper functions to visualize where the model was looking in the image when it made it's predictions. Let's not change any of this code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cgGROo2xwBrT"
   },
   "outputs": [],
   "source": [
    "CAM = oct_model\n",
    "def get_heatmap(image_class, preprocessed_image):\n",
    "    feature_weight = CAM.layers[-1].get_weights()[0]\n",
    "    features_map = CAM.layers[-4]\n",
    "\n",
    "    output = tf.keras.backend.function(\n",
    "        [CAM.layers[0].input], \n",
    "        [features_map.output, CAM.layers[-1].output])\n",
    "\n",
    "    [raw_output, _] = output(preprocessed_image)\n",
    "    raw_output = raw_output[0, :, :, :]\n",
    "\n",
    "    cam = np.zeros(dtype=np.float32, shape=raw_output.shape[0:2])\n",
    "\n",
    "    for index, weight in enumerate(feature_weight[:, image_class]):\n",
    "        cam += weight * raw_output[:, :, index]\n",
    "\n",
    "\n",
    "    cam /= np.max(cam)\n",
    "    cam = cv2.resize(cam, (img_size, img_size))\n",
    "    heatmap = cv2.applyColorMap(np.uint8(255 * cam), cv2.COLORMAP_JET) \n",
    "    heatmap[np.where(cam < 0)] = 0\n",
    "    \n",
    "    return heatmap\n",
    "\n",
    "def heat_map(image_path, image_class):        \n",
    "    img = cv2.imread(image_path)\n",
    "    img = cv2.resize(img, (224,224))\n",
    "\n",
    "    preprocessed_image = preprocess_input(img)\n",
    "    preprocessed_image = np.expand_dims(preprocessed_image, axis=0)\n",
    "\n",
    "    heatmap = get_heatmap(image_class, preprocessed_image)\n",
    "    y_pred = CAM(preprocessed_image)\n",
    "\n",
    "    result = cv2.addWeighted(img, 1, heatmap, 0.4, 0)\n",
    "    \n",
    "    heatmap = cv2.cvtColor(heatmap, cv2.COLOR_BGR2RGB)\n",
    "    result = cv2.cvtColor(result, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    fig, ax = plt.subplots(1, 3, figsize=(13, 13))\n",
    "    \n",
    "    ax[0].imshow(img)\n",
    "    ax[0].axis('off')\n",
    "    ax[0].set_title(f'True value: {class_labels_short[i]}, Model Prediction: {class_labels_short[np.argmax(y_pred)]}')\n",
    "    \n",
    "    ax[1].imshow(heatmap)\n",
    "    ax[1].axis('off')\n",
    "    \n",
    "    ax[2].imshow(result)\n",
    "    ax[2].axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yWysVATf6t6v"
   },
   "outputs": [],
   "source": [
    "cnv_path = \"OCT2017/test/CNV\"              # 0\n",
    "dme_path = \"OCT2017/test/DME\"              # 1  \n",
    "drusen_path = \"OCT2017/test/DRUSEN\"        # 2\n",
    "normal_path = \"OCT2017/test/NORMAL\"        # 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 7751,
     "status": "ok",
     "timestamp": 1569014494812,
     "user": {
      "displayName": "Tuyen Ho Sy",
      "photoUrl": "",
      "userId": "07941590644325363329"
     },
     "user_tz": -420
    },
    "id": "beSkcj-L6vAc",
    "outputId": "e3e3ea96-2689-4781-d195-15cfd4818506"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "\n",
    "oct_model.load_weights('weights.h5')\n",
    "\n",
    "# Change index for testing new image (0 =< index =< 999)\n",
    "index = 0\n",
    "\n",
    "for i in range(num_classes):\n",
    "    plt.figure(i)    \n",
    "    \n",
    "    if i == 0:\n",
    "        path = cnv_path + '/' + os.listdir(cnv_path)[index]\n",
    "    elif i == 1:\n",
    "        path = dme_path + '/' + os.listdir(dme_path)[index]\n",
    "    elif i == 2:\n",
    "        path = drusen_path + '/' + os.listdir(drusen_path)[index]\n",
    "    else:\n",
    "        path = normal_path + '/' + os.listdir(normal_path)[index]\n",
    "\n",
    "    heat_map(path, i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Resources if you're interested in more colab tutorials\n",
    "\n",
    "* To learn more about how colab works and find other tutorials: https://colab.research.google.com/notebooks/intro.ipynb#\n",
    "* Run a pose detection algorithm on youtube videos: https://colab.research.google.com/github/tugstugi/dl-colab-notebooks/blob/master/notebooks/OpenPose.ipynb\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "CAM.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
