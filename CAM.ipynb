{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. What is Machine Learning / AI ?\n",
    "Instead of coding a program with specific instructions, the goal of machine learning/AI is to \"train\" an algorithm so it can make decisions for itself.\n",
    "\n",
    "### Example: Snapchat filter\n",
    "In a Snapchat, or other apps you can download on a phone, you can select filters like \"bunny ears\" or \"sunglasses\".\n",
    "\n",
    "![image](./snapchat.png)\n",
    "[Source: https://www.flickr.com/photos/63405864@N04/27265562262]\n",
    "\n",
    "When you have the filter on, the sunglasses are (most of the time) in the right spot. How does it know how to do that if the program has never seen your face before? There are two main steps involved that the developers do:\n",
    "1. Train an AI model to predict the location of eyes/ears from a big, labelled dataset of human faces.\n",
    "2. When running on your phone. The same model predicts where your eyes are, and a separate function will put an image of sunglasses over that location on your face.\n",
    "\n",
    "### Example: Avatar livestream\n",
    "The same technique can be used to create a live avatar of YOU!\n",
    "https://pose-animator-demo.firebaseapp.com/camera.html\n",
    "On this webpage, with your webcam enabled, you will see a live video stream of yourself, and an cartoon avatar that will move when you move, and make the same faces you make.\n",
    "\n",
    "!!! Will not work if you are using your webcam on Zoom or another application !!! \n",
    "\n",
    "\n",
    "# 2. AI in Healthcare\n",
    "In addition to a lot of the cool looking demo's out there. There are a lot of applications of AI that have the potential to make huge, positive impacts on our communitys. One of those applications is in the healthcare industry. By looking at patient images (could be X-Ray, brain MRI, lung CT), we can potentially train AI models to make predictions about whether patients are at risk for disease, and speed up their interactions with doctors, clinicians when they are high-risk.\n",
    "\n",
    "One interesting body part that tells us a lot of information about a person's health is the eye. There are a lot of diseases that can be detected early on, when looking at images of the eye. On top of vision-related issues like near-sightedness, with different kinds of images of the eye, doctors are able to diagnose diabetes, heart conditions, alzheimers (in some cases) when these diseases are at early stages.\n",
    "\n",
    "## Example: Looking at the retina with an OCT eye scan.\n",
    "The retina is a part of your the back of your eye:\n",
    "![retina](retina.png)\n",
    "\n",
    "By using a imaging technique called OCT (Optical Coherence Tomography), we can compute an image similar to the one below that visualizes the retina, fovea, and other regions usefull for disease diagnosis. Some OCT images are shown below, some healthy, some unhealthy.\n",
    "\n",
    "//TOOD\n",
    "\n",
    "In practice, doctors look at these OCT images when trying to disagnose retinal diseases, and guide treatment for their patients. \n",
    "\n",
    "\n",
    "# 3. Can we train an AI model to predict different disease types from an eye scan?\n",
    "That is our goal for today! Today we will cover the complete cycle of training an AI model including:\n",
    "1. Loading and visualizing the data\n",
    "2. Building the AI model\n",
    "3. Training the AI model\n",
    "4. Visualizing the AI model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tls5m1zVLFjg"
   },
   "source": [
    "# Let's Start Coding!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mGxu-kfgLX_f"
   },
   "source": [
    "## 1. Download OCT2017 dataset\n",
    "This will download the dataset to the location this code runs in. *It will not download it to your computer*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 309
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 226141,
     "status": "ok",
     "timestamp": 1569013480329,
     "user": {
      "displayName": "Tuyen Ho Sy",
      "photoUrl": "",
      "userId": "07941590644325363329"
     },
     "user_tz": -420
    },
    "id": "4WnZYEhAy_0w",
    "outputId": "39c1a330-25d9-4e64-c6c1-c36583225233"
   },
   "outputs": [],
   "source": [
    "# Download dataset\n",
    "# !wget https://data.mendeley.com/datasets/rscbjbr9sj/2/files/5699a1d8-d1b6-45db-bb92-b61051445347/OCT2017.tar.gz\n",
    "\n",
    "# Decompress dataset\n",
    "# !tar -zxf OCT2017.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "x97l--gCLu0I"
   },
   "source": [
    "## 2. Setup Programming Environment\n",
    "In industry, we never start from scratch. We use tools that make it easier to load data, build AI models, and train and visualize them. Let's make sure these tools are in our coding environment!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ehSSO-Rqza_g"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2, preprocess_input\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "X0ZObTZRL7V7"
   },
   "source": [
    "## 3. Preprocess dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4978,
     "status": "ok",
     "timestamp": 1569013852154,
     "user": {
      "displayName": "Tuyen Ho Sy",
      "photoUrl": "",
      "userId": "07941590644325363329"
     },
     "user_tz": -420
    },
    "id": "ulKOSk_bL-pb",
    "outputId": "95af13e8-14f2-407d-fe15-d3a91e3a6e58"
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "img_size = 224\n",
    "input_img_size = (224,224,3)\n",
    "class_labels_short = ['CNV', 'DME', 'DRUSEN', 'NORMAL']\n",
    "class_labels_long = ['choroidal neovascularization', 'diabetic macular edema', 'drusen', 'normal']\n",
    "\n",
    "\n",
    "###############################################\n",
    "# Training Data\n",
    "train_data_preprocessing = ImageDataGenerator(\n",
    "      brightness_range=None, \n",
    "      shear_range=0.0,\n",
    "      zoom_range=0.0,\n",
    "      horizontal_flip=False,\n",
    "      vertical_flip=False, \n",
    "      rescale=None, \n",
    "      preprocessing_function=preprocess_input,\n",
    "      data_format=None, \n",
    "      subset='train',\n",
    "      validation_split=0.2)\n",
    "\n",
    "train_data = train_data_preprocessing.flow_from_directory(\n",
    "    'OCT2017/train',\n",
    "    target_size=(img_size, img_size),\n",
    "    color_mode='rgb',\n",
    "    shuffle=True,\n",
    "    batch_size=batch_size)\n",
    "\n",
    "###############################################\n",
    "# Testing Data\n",
    "test_data_preprocessing = ImageDataGenerator(\n",
    "    preprocessing_function=preprocess_input)\n",
    "\n",
    "test_data = test_data_preprocessing.flow_from_directory(\n",
    "                'OCT2017/test',\n",
    "                target_size=(img_size, img_size),\n",
    "                color_mode='rgb',\n",
    "                shuffle=False,\n",
    "                batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_some_images(train_iter, nb_image_rows=15, nb_images_per_row=3):\n",
    "    nb_images_per_row = 3\n",
    "    train_iter.batch_size=nb_images_per_row\n",
    "    for i in range(nb_image_rows):\n",
    "        x_batch, y_batch = train_iter.next()\n",
    "        x_batch += 1\n",
    "        x_batch /= 2\n",
    "\n",
    "        plt.figure()\n",
    "        fig, axes =  plt.subplots(nrows=1, ncols=nb_images_per_row, figsize=(20,15))\n",
    "        for ax, x, y in zip(axes, x_batch, y_batch):\n",
    "            ax.imshow(x)\n",
    "            ax.set_title(class_labels_long[np.argmax(y)])\n",
    "            ax.set_xticks([])\n",
    "            ax.set_yticks([])\n",
    "\n",
    "        plt.show()\n",
    "    \n",
    "plot_some_images(train_data, nb_image_rows=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SY-5jSaKmSZU"
   },
   "source": [
    "## 4. Build Original MobileNetV2 for Classification Task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4976,
     "status": "ok",
     "timestamp": 1568808214298,
     "user": {
      "displayName": "Tuyen Ho Sy",
      "photoUrl": "",
      "userId": "07941590644325363329"
     },
     "user_tz": -420
    },
    "id": "2HfIHciVkidK",
    "outputId": "0ad69a1e-80af-4fa5-b0af-9fbc9aee4570"
   },
   "outputs": [],
   "source": [
    "def Original_model():\n",
    "    mobile_net_v2 = MobileNetV2(\n",
    "                    weights=None,\n",
    "                    input_shape=input_img_size,\n",
    "                    alpha=1,\n",
    "                    include_top=False)\n",
    "    for layer in mobile_net_v2.layers:\n",
    "        layer.trainable = True\n",
    "        \n",
    "    model = mobile_net_v2.layers[-1].output\n",
    "    model = tf.keras.layers.Flatten()(model)\n",
    "    model = tf.keras.layers.Dense(num_classes, activation='softmax', kernel_initializer='uniform')(model)\n",
    "    model = tf.keras.models.Model(inputs=mobile_net_v2.input, outputs=model)\n",
    "    \n",
    "    return model\n",
    "\n",
    "Original = Original_model()\n",
    "Original.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5SVQI-kdqxgb"
   },
   "source": [
    "## 5. Train Original MobileNetV2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 462
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 9542579,
     "status": "ok",
     "timestamp": 1568817974202,
     "user": {
      "displayName": "Tuyen Ho Sy",
      "photoUrl": "",
      "userId": "07941590644325363329"
     },
     "user_tz": -420
    },
    "id": "sktJFYyKQoG9",
    "outputId": "7c82a300-756b-41ef-b826-240aa7c05c93"
   },
   "outputs": [],
   "source": [
    "# polynomial decay\n",
    "def polynomial_decay(epoch):\n",
    "    power = 1.0\n",
    "    alpha = learning_rate*(1-(epoch/float(n_epochs)))**power\n",
    "    return alpha\n",
    "\n",
    "\n",
    "# Hyper-parameter\n",
    "learning_rate = 3e-4\n",
    "n_epochs = 6\n",
    "\n",
    "# Save checkpoint\n",
    "weights_name = \"{epoch:01d}|train_acc{acc:.3f}|val_acc={val_acc:.3f}.h5\"\n",
    "checkpoint = ModelCheckpoint(weights_name, monitor=\"val_acc\", verbose=1, save_best_only=True,\n",
    "                             save_weights_only=True, mode=\"max\", period=1)\n",
    "\n",
    "# Learning rate\n",
    "lr_decay = LearningRateScheduler(polynomial_decay)\n",
    "\n",
    "    # Optimizer\n",
    "    optimizer = tf.keras.optimizers.SGD(lr=learning_rate, momentum=0.9)\n",
    "    Original.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['acc'])\n",
    "\n",
    "# Steps per train epoch\n",
    "train_steps = int(83484/batch_size)\n",
    "# Steps per test epoch\n",
    "test_steps = int(1000/batch_size)\n",
    "\n",
    "trained_model_original = Original.fit_generator(train,\n",
    "                                epochs=n_epochs,\n",
    "                                steps_per_epoch=train_steps,\n",
    "                                callbacks=[checkpoint, lr_decay],\n",
    "                                validation_data=test,\n",
    "                                validation_steps=test_steps,\n",
    "                                verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "n1XOQ4hUPBXH"
   },
   "source": [
    "## 6. Build CAM model base on MobileNetV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5344,
     "status": "ok",
     "timestamp": 1569013863455,
     "user": {
      "displayName": "Tuyen Ho Sy",
      "photoUrl": "",
      "userId": "07941590644325363329"
     },
     "user_tz": -420
    },
    "id": "je6kK5QYPEk7",
    "outputId": "16048ad6-4dc2-40d5-d962-be35b310bd2b"
   },
   "outputs": [],
   "source": [
    "num_classes = 4\n",
    "\n",
    "def CAM_model():\n",
    "    mobile_net_v2 = MobileNetV2(\n",
    "                    weights=None,\n",
    "                    input_shape=input_img_size,\n",
    "                    alpha=1,\n",
    "                    include_top=False)\n",
    "    for layer in mobile_net_v2.layers:\n",
    "        layer.trainable = True\n",
    "        \n",
    "    model = mobile_net_v2.layers[-3].output\n",
    "    model = tf.keras.layers.GlobalAveragePooling2D()(model)\n",
    "    model = tf.keras.layers.Dense(num_classes, activation='softmax', kernel_initializer='uniform')(model)\n",
    "    model = tf.keras.models.Model(inputs=mobile_net_v2.input, outputs=model)\n",
    "    \n",
    "    return model\n",
    "\n",
    "CAM = CAM_model()\n",
    "CAM.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "X19VIWwPRlsV"
   },
   "source": [
    "## 7. Train CAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 462
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 9491526,
     "status": "ok",
     "timestamp": 1568808109481,
     "user": {
      "displayName": "Tuyen Ho Sy",
      "photoUrl": "",
      "userId": "07941590644325363329"
     },
     "user_tz": -420
    },
    "id": "pA5i1kJ3RngM",
    "outputId": "8ad63443-05af-453d-a354-884ecd8511c8"
   },
   "outputs": [],
   "source": [
    "# Hyper-parameter\n",
    "learning_rate = 3e-4\n",
    "n_epochs = 6\n",
    "\n",
    "# Save checkpoint\n",
    "weights_name = \"{epoch:01d}|train_acc{acc:.3f}|val_acc={val_acc:.3f}.h5\"\n",
    "checkpoint = ModelCheckpoint(weights_name, monitor=\"val_acc\", verbose=1, save_best_only=True,\n",
    "                             save_weights_only=True, mode=\"max\", period=1)\n",
    "\n",
    "# Learning rate\n",
    "lr_decay = LearningRateScheduler(polynomial_decay)\n",
    "\n",
    "# Optimizer\n",
    "optimizer = tf.keras.optimizers.SGD(lr=learning_rate, momentum=0.9)\n",
    "CAM.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['acc'])\n",
    "\n",
    "# Steps per train epoch\n",
    "train_steps = int(83484/batch_size)\n",
    "# Steps per test epoch\n",
    "test_steps = int(1000/batch_size)\n",
    "\n",
    "trained_model_CAM = CAM.fit_generator(train,\n",
    "                                epochs=n_epochs,\n",
    "                                steps_per_epoch=train_steps,\n",
    "                                callbacks=[checkpoint, lr_decay],\n",
    "                                validation_data=test,\n",
    "                                validation_steps=test_steps,\n",
    "                                verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "c0t8PoAht6l1"
   },
   "source": [
    "## 8. Summary Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 292
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 976,
     "status": "ok",
     "timestamp": 1568818829304,
     "user": {
      "displayName": "Tuyen Ho Sy",
      "photoUrl": "",
      "userId": "07941590644325363329"
     },
     "user_tz": -420
    },
    "id": "2k_sMGvmt_GH",
    "outputId": "70f4d82d-42df-408d-9852-437c83464259"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "validation_acc_CAM = trained_model_CAM.history['val_acc']\n",
    "validation_acc_Ori = trained_model_original.history['val_acc']\n",
    "                                                        \n",
    "epochs = range(6)\n",
    "                                                        \n",
    "plt.plot(epochs, validation_acc_CAM, 'g', label='validation accuracy CAM')\n",
    "plt.plot(epochs, validation_acc_Ori, 'b', label='validation accuracy Original')\n",
    "                                                        \n",
    "plt.ylim(bottom=0)\n",
    "plt.xlabel('Epoch', fontsize=20)\n",
    "plt.ylabel('Accuracy', fontsize=20)\n",
    "\n",
    "note = 'lower right'\n",
    "plt.legend(loc=note)\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YzYyddNxv2fg"
   },
   "source": [
    "## 9. Label Heat Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cgGROo2xwBrT"
   },
   "outputs": [],
   "source": [
    "def get_heatmap(image_class, preprocessed_image):\n",
    "    feature_weight = CAM.layers[-1].get_weights()[0]\n",
    "    features_map = CAM.layers[-3]\n",
    "\n",
    "    output = tf.keras.backend.function([CAM.layers[0].input], \n",
    "                                           [features_map.output, CAM.layers[-1].output])\n",
    "\n",
    "    [raw_output, _] = output(preprocessed_image)\n",
    "    raw_output = raw_output[0, :, :, :]\n",
    "\n",
    "    cam = np.zeros(dtype=np.float32, shape=raw_output.shape[0:2])\n",
    "\n",
    "    for index, weight in enumerate(feature_weight[:, image_class]):\n",
    "        cam += weight * raw_output[:, :, index]\n",
    "\n",
    "\n",
    "    cam /= np.max(cam)\n",
    "    cam = cv2.resize(cam, (img_size, img_size))\n",
    "    heatmap = cv2.applyColorMap(np.uint8(255 * cam), cv2.COLORMAP_JET) \n",
    "    heatmap[np.where(cam < 0)] = 0\n",
    "    \n",
    "    return heatmap\n",
    "\n",
    "def heat_map(image_path, image_class):        \n",
    "    img = cv2.imread(image_path)\n",
    "    img = cv2.resize(img, (224,224))\n",
    "\n",
    "    preprocessed_image = preprocess_input(img)\n",
    "    preprocessed_image = np.expand_dims(preprocessed_image, axis=0)\n",
    "\n",
    "    heatmap = get_heatmap(image_class, preprocessed_image)\n",
    "\n",
    "    result = cv2.addWeighted(img, 1, heatmap, 0.4, 0)\n",
    "    \n",
    "    heatmap = cv2.cvtColor(heatmap, cv2.COLOR_BGR2RGB)\n",
    "    result = cv2.cvtColor(result, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    fig, ax = plt.subplots(1, 3, figsize=(13, 13))\n",
    "    \n",
    "    ax[0].imshow(img)\n",
    "    ax[0].axis('off')\n",
    "    \n",
    "    ax[1].imshow(heatmap)\n",
    "    ax[1].axis('off')\n",
    "    \n",
    "    ax[2].imshow(result)\n",
    "    ax[2].axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yWysVATf6t6v"
   },
   "outputs": [],
   "source": [
    "cnv_path = \"OCT2017/test/CNV\"              # 0\n",
    "dme_path = \"OCT2017/test/DME\"              # 1  \n",
    "drusen_path = \"OCT2017/test/DRUSEN\"        # 2\n",
    "normal_path = \"OCT2017/test/NORMAL\"        # 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 7751,
     "status": "ok",
     "timestamp": 1569014494812,
     "user": {
      "displayName": "Tuyen Ho Sy",
      "photoUrl": "",
      "userId": "07941590644325363329"
     },
     "user_tz": -420
    },
    "id": "beSkcj-L6vAc",
    "outputId": "e3e3ea96-2689-4781-d195-15cfd4818506"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "# load your best CAM model\n",
    "# CAM.load_weights('<best CAM model path>.h5')\n",
    "\n",
    "CAM.load_weights('epoch=05_accuracy=0.9252_val_accuracy=0.9819.h5')\n",
    "\n",
    "# Change index for testing new image (0 =< index =< 999)\n",
    "index = 0\n",
    "\n",
    "for i in range(num_classes):\n",
    "    plt.figure(i)    \n",
    "    \n",
    "    if i == 0:\n",
    "        path = cnv_path + '/' + os.listdir(cnv_path)[index]\n",
    "    elif i == 1:\n",
    "        path = dme_path + '/' + os.listdir(dme_path)[index]\n",
    "    elif i == 2:\n",
    "        path = drusen_path + '/' + os.listdir(drusen_path)[index]\n",
    "    else:\n",
    "        path = normal_path + '/' + os.listdir(normal_path)[index]\n",
    "\n",
    "    heat_map(path, i)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "CAM.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3.6.7 64-bit ('dev_rsync': virtualenv)",
   "language": "python",
   "name": "python36764bitdevrsyncvirtualenvfe53707d4cef44249de4a9c862da04ab"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
